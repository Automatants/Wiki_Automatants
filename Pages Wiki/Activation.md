---
author: 'Thomas LEMERCIER'
date: '2021-12-27 (last update)'
description: ''
---

# Activations

Activations play a major role in a network, without them any network would be equivalent to a single dense layer because the whole network would be linear. Activations allow us to build deep neural networks. There are a lot of activations but they often don't play a major role in the final result of your network as long as they are non-linear. However, they can greatly influence the number of iterations for your network to converge.

The more mainstream activations are :
 - [[Sigmoid]]
 - [[Tanh]]
- [[ReLU]]